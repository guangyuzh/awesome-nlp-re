{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train txt file for thunlp/TensorFlow-NRE from wikipedia-biography dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 13:51:32) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "# Checking Python Version 3+ \n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link files\n",
    "\n",
    "train.title -1-1-> train.box -1-1-> train.nb -[number]-1-> train.sent\n",
    "\n",
    "\n",
    "## Resule Schema:\n",
    "title, non_na_box, accumulated_sent_context\n",
    "\n",
    "## Sample Training Data from thunlp/TensorFlow-NRE:\n",
    "#### Format: (fb_mid_e1, fb_mid_e2, e1_name, e2_name, relation, sentence)   \n",
    "\n",
    "### Sample:    \n",
    "\n",
    "fb_mid_e1 - m.0ccvx   \n",
    "fb_mid_e2 - m.05gf08   \n",
    "e1_name   - queens   \n",
    "e2_name   - belle_harbor   \n",
    "relation  - /location/location/contains   \n",
    "sentence  - sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet in belle_harbor , queens , because equipment failure , not pilot error , might have been the cause . ###END###   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wikipedia biography training files\n",
    "# substitute test and validate files\n",
    "data_type = 'valid' # test, valid\n",
    "train_title_file = data_type + '/' + data_type + \".title\"\n",
    "train_nb_file    = data_type + '/' + data_type + \".nb\"\n",
    "train_sent_file  = data_type + '/' + data_type + \".sent\"\n",
    "train_box_file   = data_type + '/' + data_type + \".box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pope michael iii of alexandria -lrb- also known as khail iii -rrb- was the coptic pope of alexandria and patriarch of the see of st. mark -lrb- 880 -- 907 -rrb- .\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add line indexer for the sent file\n",
    "nbs_dict = {}\n",
    "with open(train_sent_file) as sent:\n",
    "    for line, content in enumerate(sent):\n",
    "        nbs_dict[line] = content\n",
    "    \n",
    "nbs_dict.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words from a context string, i.e., -lrb-\n",
    "useless_words_to_remove = ['-lrb-', '-rrb-', '.\\n', '']\n",
    "\n",
    "def cleanUpSentence(input_sent):\n",
    "    keywords_to_remove = useless_words_to_remove\n",
    "    querywords = input_sent.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in keywords_to_remove]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "send_index = 0\n",
    "\n",
    "sent_dict = {}\n",
    "\n",
    "with open(train_nb_file) as nbs:\n",
    "    accumulated_lines = 0\n",
    "    for nb in nbs:\n",
    "        current_lines_to_read = int(nb)\n",
    "        \n",
    "        current_accumulated_sent_context = ''\n",
    "        \n",
    "        for i in range(current_lines_to_read):\n",
    "            line_to_read = accumulated_lines + i\n",
    "            current_accumulated_sent_context += cleanUpSentence(nbs_dict.get(line_to_read))\n",
    "        \n",
    "        accumulated_lines += current_lines_to_read\n",
    "\n",
    "        sent_dict[send_index] = current_accumulated_sent_context\n",
    "        send_index += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hui jun is a male former table tennis player from china .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 100 most shown relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relations_stat_dict = defaultdict(int)\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        \n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        for attr in filtered_attrs:\n",
    "            if '_1:' in attr:\n",
    "                attr_label = attr.split(':')[0][:-2]\n",
    "                relations_stat_dict[attr_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumVal = 0\n",
    "for i in relations_stat_dict:\n",
    "    value = relations_stat_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_most_shown_relations = {} # relation_label, number_of_times_it_shown\n",
    "sortedValues = sorted(relations_stat_dict.values(), reverse=True)\n",
    "max_value = sortedValues[0]\n",
    "top_50_value = sortedValues[49]\n",
    "for attr_label in relations_stat_dict:\n",
    "    attr_rep = relations_stat_dict[attr_label]\n",
    "    if attr_rep >= top_50_value:\n",
    "        top_most_shown_relations[attr_label] = attr_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 66734, 'predecessor': 6966, 'successor': 6266, 'birth_place': 57282, 'death_date': 21656, 'nationality': 13886, 'religion': 3968, 'residence': 4581, 'article_title': 72831, 'fullname': 13223, 'height': 13002, 'birth_date': 63212, 'currentclub': 6813, 'clubnumber': 4161, 'position': 19150, 'years': 12920, 'clubs': 11739, 'caps': 10374, 'goals': 10775, 'pcupdate': 4466, 'term_start': 7742, 'term_end': 6418, 'party': 6705, 'alma_mater': 6891, 'spouse': 8928, 'image': 26790, 'caption': 15578, 'occupation': 18943, 'years_active': 7638, 'image_size': 6682, 'debutyear': 3232, 'background': 5886, 'origin': 3587, 'genre': 6299, 'label': 3775, 'associated_acts': 3161, 'death_place': 16746, 'birth_name': 9367, 'nationalyears': 5278, 'nationalteam': 5685, 'nationalcaps': 5051, 'nationalgoals': 5028, 'youthyears': 4125, 'youthclubs': 5942, 'website': 3952, 'children': 4527, 'weight': 4594, 'office': 5115, 'known_for': 3347, 'awards': 3727}\n"
     ]
    }
   ],
   "source": [
    "print(top_most_shown_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the relation2id.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Remove the following relation labels for speeding up:\n",
    "del top_most_shown_relations['clubs']\n",
    "del top_most_shown_relations['years']\n",
    "del top_most_shown_relations['image']\n",
    "del top_most_shown_relations['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_type == 'train':\n",
    "    relation2idFile = open(data_type+'/relation2id.generate.txt', \"w\") \n",
    "    relation2idFile.write('NA 0\\n')\n",
    "    relationid = 1\n",
    "    for relation in top_most_shown_relations:\n",
    "        relation2idFile.write(relation+' '+str(relationid)+'\\n')\n",
    "        relationid += 1\n",
    "    relation2idFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Concatenated Relation Labels:\n",
    "Current, the relation labels are splitted in the wikipedia biography dataset.  \n",
    "In order to adapt to NRE code, we have to concatenate all splitted labels into one single string with underscore in between.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_relation_label_and_value_list = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        current_box_dict = {}\n",
    "        for oneLabel in filtered_attrs:\n",
    "            labelStringOnly = oneLabel.split(':')[0].split('_')[0]\n",
    "            if labelStringOnly in top_most_shown_relations:\n",
    "                currentValue = cleanUpSentence(oneLabel.split(':')[1])\n",
    "                if labelStringOnly in current_box_dict:\n",
    "                    current_box_dict[labelStringOnly] = current_box_dict[labelStringOnly] + '_' + currentValue\n",
    "                else:\n",
    "                    current_box_dict[labelStringOnly] = currentValue\n",
    "               \n",
    "        real_relation_label_and_value_list.append(current_box_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72831\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(real_relation_label_and_value_list))\n",
    "print(len(real_relation_label_and_value_list) == len(sent_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nationality': 'egyptian',\n",
       " 'predecessor': 'shenouda_i',\n",
       " 'religion': 'coptic_orthodox_christian',\n",
       " 'residence': \"saint_mark_'s_church\",\n",
       " 'successor': 'gabriel_i'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_relation_label_and_value_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data txt file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the titles into a list, in original order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_list = []\n",
    "with open(train_title_file) as titles:\n",
    "    for title in titles:\n",
    "        title_arr = title.split(' ')\n",
    "        current_title = ''\n",
    "        for t in title_arr:\n",
    "            current_title += t+'_'\n",
    "        title_list.append(current_title[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the three lists (title_list, sent_dict, and real_relation_label_and_value_list) start with index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marie_stephan'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marie stephan , born march 14 , 1996 is a professional squash player who represents france .she reached a career-high world ranking of world no. 101 in july 2015 .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shenouda_i\n",
      "gabriel_i\n",
      "egyptian\n",
      "coptic_orthodox_christian\n",
      "saint_mark_'s_church\n"
     ]
    }
   ],
   "source": [
    "for i in real_relation_label_and_value_list[0]:\n",
    "    print(real_relation_label_and_value_list[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join three list by the biography title and write to text file:\n",
    "This is going to generate a 1+ GB large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultFile = open(data_type+'/'+data_type+\".generate.txt\", \"w\") \n",
    "\n",
    "index = 0\n",
    "\n",
    "for relationAndValueEntry in real_relation_label_and_value_list:\n",
    "    for relationName in relationAndValueEntry:\n",
    "        resultFile.write('SH\\tSH\\t')\n",
    "        resultFile.write(title_list[index])\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(relationAndValueEntry[relationName])\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(relationName)\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(sent_dict[index])\n",
    "        resultFile.write(' ###END###\\n')\n",
    "    index += 1\n",
    "\n",
    "resultFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
