{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train txt file for thunlp/TensorFlow-NRE from wikipedia-biography dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 13:51:32) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "# Checking Python Version 3+ \n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link files\n",
    "\n",
    "train.title -1-1-> train.box -1-1-> train.nb -[number]-1-> train.sent\n",
    "\n",
    "\n",
    "## Resule Schema:\n",
    "title, non_na_box, accumulated_sent_context\n",
    "\n",
    "## Sample Training Data from thunlp/TensorFlow-NRE:\n",
    "#### Format: (fb_mid_e1, fb_mid_e2, e1_name, e2_name, relation, sentence)   \n",
    "\n",
    "### Sample:    \n",
    "\n",
    "fb_mid_e1 - m.0ccvx   \n",
    "fb_mid_e2 - m.05gf08   \n",
    "e1_name   - queens   \n",
    "e2_name   - belle_harbor   \n",
    "relation  - /location/location/contains   \n",
    "sentence  - sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet in belle_harbor , queens , because equipment failure , not pilot error , might have been the cause . ###END###   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wikipedia biography training files\n",
    "# substitute test and validate files\n",
    "data_type = 'train' # test, valid\n",
    "train_title_file = data_type + '/' + data_type + \".title\"\n",
    "train_nb_file    = data_type + '/' + data_type + \".nb\"\n",
    "train_sent_file  = data_type + '/' + data_type + \".sent\"\n",
    "train_box_file   = data_type + '/' + data_type + \".box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walter extra is a german award-winning aerobatic pilot , chief aircraft designer and founder of extra flugzeugbau -lrb- extra aircraft construction -rrb- , a manufacturer of aerobatic aircraft .\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add line indexer for the sent file\n",
    "nbs_dict = {}\n",
    "with open(train_sent_file) as sent:\n",
    "    for line, content in enumerate(sent):\n",
    "        nbs_dict[line] = content\n",
    "    \n",
    "nbs_dict.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words from a context string, i.e., -lrb-\n",
    "useless_words_to_remove = ['-lrb-', '-rrb-', '.\\n', '']\n",
    "\n",
    "def cleanUpSentence(input_sent):\n",
    "    keywords_to_remove = useless_words_to_remove\n",
    "    querywords = input_sent.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in keywords_to_remove]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "send_index = 0\n",
    "\n",
    "sent_dict = {}\n",
    "\n",
    "with open(train_nb_file) as nbs:\n",
    "    accumulated_lines = 0\n",
    "    for nb in nbs:\n",
    "        current_lines_to_read = int(nb)\n",
    "        \n",
    "        current_accumulated_sent_context = ''\n",
    "        \n",
    "        for i in range(current_lines_to_read):\n",
    "            line_to_read = accumulated_lines + i\n",
    "            current_accumulated_sent_context += cleanUpSentence(nbs_dict.get(line_to_read))\n",
    "        \n",
    "        accumulated_lines += current_lines_to_read\n",
    "\n",
    "        sent_dict[send_index] = current_accumulated_sent_context\n",
    "        send_index += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aaron hohlbein born august 16 , 1985 in middleton , wisconsin is an american soccer player who is currently without a club .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top 100 most shown relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relations_stat_dict = defaultdict(int)\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        \n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        for attr in filtered_attrs:\n",
    "            if '_1:' in attr:\n",
    "                attr_label = attr.split(':')[0][:-2]\n",
    "                relations_stat_dict[attr_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumVal = 0\n",
    "for i in relations_stat_dict:\n",
    "    value = relations_stat_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_most_shown_relations = {} # relation_label, number_of_times_it_shown\n",
    "sortedValues = sorted(relations_stat_dict.values(), reverse=True)\n",
    "max_value = sortedValues[0]\n",
    "top_50_value = sortedValues[49]\n",
    "for attr_label in relations_stat_dict:\n",
    "    attr_rep = relations_stat_dict[attr_label]\n",
    "    if attr_rep >= top_50_value:\n",
    "        top_most_shown_relations[attr_label] = attr_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 534280, 'birth_date': 506204, 'nationality': 110955, 'occupation': 151709, 'article_title': 582659, 'fullname': 106788, 'birth_place': 457199, 'height': 104328, 'position': 153790, 'youthyears': 32792, 'youthclubs': 47767, 'years': 102852, 'clubs': 93910, 'caps': 83140, 'goals': 86378, 'pcupdate': 36152, 'image': 215753, 'death_date': 172806, 'death_place': 133669, 'known_for': 26801, 'alma_mater': 55856, 'party': 52852, 'currentclub': 55278, 'clubnumber': 33809, 'nationalyears': 42840, 'nationalteam': 46144, 'nationalcaps': 41029, 'nationalgoals': 40824, 'office': 40768, 'term_start': 60869, 'term_end': 51045, 'predecessor': 54786, 'successor': 49415, 'spouse': 71480, 'caption': 123782, 'religion': 31667, 'website': 32736, 'image_size': 54541, 'awards': 29345, 'children': 35861, 'background': 47437, 'years_active': 61173, 'birth_name': 75174, 'debutyear': 25660, 'residence': 35938, 'weight': 36150, 'genre': 50744, 'label': 30367, 'associated_acts': 25071, 'origin': 28813}\n"
     ]
    }
   ],
   "source": [
    "print(top_most_shown_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the relation2id.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Remove the following relation labels for speeding up:\n",
    "del top_most_shown_relations['clubs']\n",
    "del top_most_shown_relations['years']\n",
    "del top_most_shown_relations['image']\n",
    "del top_most_shown_relations['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_type == 'train':\n",
    "    relation2idFile = open(data_type+'/relation2id.generate.txt', \"w\") \n",
    "    relation2idFile.write('NA 0\\n')\n",
    "    relationid = 1\n",
    "    for relation in top_most_shown_relations:\n",
    "        relation2idFile.write(relation+' '+str(relationid)+'\\n')\n",
    "        relationid += 1\n",
    "    relation2idFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Concatenated Relation Labels:\n",
    "Current, the relation labels are splitted in the wikipedia biography dataset.  \n",
    "In order to adapt to NRE code, we have to concatenate all splitted labels into one single string with underscore in between.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_relation_label_and_value_list = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        current_box_dict = {}\n",
    "        for oneLabel in filtered_attrs:\n",
    "            labelStringOnly = oneLabel.split(':')[0].split('_')[0]\n",
    "            if labelStringOnly in top_most_shown_relations:\n",
    "                currentValue = cleanUpSentence(oneLabel.split(':')[1])\n",
    "                if labelStringOnly in current_box_dict:\n",
    "                    current_box_dict[labelStringOnly] = current_box_dict[labelStringOnly] + '_' + currentValue\n",
    "                else:\n",
    "                    current_box_dict[labelStringOnly] = currentValue\n",
    "               \n",
    "        real_relation_label_and_value_list.append(current_box_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582659\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(real_relation_label_and_value_list))\n",
    "print(len(real_relation_label_and_value_list) == len(sent_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nationality': 'german', 'occupation': 'aircraft_designer_and_manufacturer'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_relation_label_and_value_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data txt file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the titles into a list, in original order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_list = []\n",
    "with open(train_title_file) as titles:\n",
    "    for title in titles:\n",
    "        title_arr = title.split(' ')\n",
    "        current_title = ''\n",
    "        for t in title_arr:\n",
    "            current_title += t+'_'\n",
    "        title_list.append(current_title[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the three lists (title_list, sent_dict, and real_relation_label_and_value_list) start with index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linda_hayden'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linda hayden born 19 january 1953 is an english film and television actress and the sister of actress jane hayden .she is best known for her roles in 1970s british horror films and sex comedies .'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german\n",
      "aircraft_designer_and_manufacturer\n"
     ]
    }
   ],
   "source": [
    "for i in real_relation_label_and_value_list[0]:\n",
    "    print(real_relation_label_and_value_list[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join three list by the biography title and write to text file:\n",
    "This is going to generate a 1+ GB large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultFile = open(data_type+'/'+data_type+\".generate.txt\", \"w\") \n",
    "\n",
    "index = 0\n",
    "\n",
    "for relationAndValueEntry in real_relation_label_and_value_list:\n",
    "    for relationName in relationAndValueEntry:\n",
    "        resultFile.write('SH\\tSH\\t')\n",
    "        resultFile.write(title_list[index])\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(relationAndValueEntry[relationName])\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(relationName)\n",
    "        resultFile.write('\\t')\n",
    "        resultFile.write(sent_dict[index])\n",
    "        resultFile.write(' ###END###\\n')\n",
    "    index += 1\n",
    "\n",
    "resultFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
