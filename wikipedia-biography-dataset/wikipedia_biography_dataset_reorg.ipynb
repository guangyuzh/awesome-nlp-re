{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Train txt file for thunlp/TensorFlow-NRE from wikipedia-biography dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 13:51:32) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "# Checking Python Version 3+ \n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link files\n",
    "\n",
    "train.title -1-1-> train.box -1-1-> train.nb -[number]-1-> train.sent\n",
    "\n",
    "\n",
    "## Resule Schema:\n",
    "title, non_na_box, accumulated_sent_context\n",
    "\n",
    "## Sample Training Data from thunlp/TensorFlow-NRE:\n",
    "#### Format: (fb_mid_e1, fb_mid_e2, e1_name, e2_name, relation, sentence)   \n",
    "\n",
    "### Sample:    \n",
    "\n",
    "fb_mid_e1 - m.0ccvx   \n",
    "fb_mid_e2 - m.05gf08   \n",
    "e1_name   - queens   \n",
    "e2_name   - belle_harbor   \n",
    "relation  - /location/location/contains   \n",
    "sentence  - sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet in belle_harbor , queens , because equipment failure , not pilot error , might have been the cause . ###END###   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wikipedia biography training files\n",
    "# substitute test and validate files\n",
    "data_type = 'test' # test, valid\n",
    "train_title_file = data_type + '/' + data_type + \".title\"\n",
    "train_nb_file    = data_type + '/' + data_type + \".nb\"\n",
    "train_sent_file  = data_type + '/' + data_type + \".sent\"\n",
    "train_box_file   = data_type + '/' + data_type + \".box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leonard shenoff randle -lrb- born february 12 , 1949 -rrb- is a former major league baseball player .\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add line indexer for the sent file\n",
    "nbs_dict = {}\n",
    "with open(train_sent_file) as sent:\n",
    "    for line, content in enumerate(sent):\n",
    "        nbs_dict[line] = content\n",
    "    \n",
    "nbs_dict.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words from a context string, i.e., -lrb-\n",
    "useless_words_to_remove = ['-lrb-', '-rrb-', '.\\n', '']\n",
    "\n",
    "def cleanUpSentence(input_sent):\n",
    "    keywords_to_remove = useless_words_to_remove\n",
    "    querywords = input_sent.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in keywords_to_remove]\n",
    "    result = ' '.join(resultwords)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "send_index = 0\n",
    "\n",
    "sent_dict = {}\n",
    "\n",
    "with open(train_nb_file) as nbs:\n",
    "    accumulated_lines = 0\n",
    "    for nb in nbs:\n",
    "        current_lines_to_read = int(nb)\n",
    "        \n",
    "        current_accumulated_sent_context = ''\n",
    "        \n",
    "        for i in range(current_lines_to_read):\n",
    "            line_to_read = accumulated_lines + i\n",
    "            current_accumulated_sent_context += cleanUpSentence(nbs_dict.get(line_to_read))\n",
    "        \n",
    "        accumulated_lines += current_lines_to_read\n",
    "\n",
    "        sent_dict[send_index] = current_accumulated_sent_context\n",
    "        send_index += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'leonard shenoff randle born february 12 , 1949 is a former major league baseball player .he was the first-round pick of the washington senators in the secondary phase of the june 1970 major league baseball draft , tenth overall .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "sent_length_dict = defaultdict(int)\n",
    "for t in sent_dict:\n",
    "    i = sent_dict[t]\n",
    "    if len(i) < 100:\n",
    "        sent_length_dict['100-'] += 1\n",
    "    if len(i) < 150:\n",
    "        sent_length_dict['100-150'] += 1\n",
    "    elif len(i) < 200:\n",
    "        sent_length_dict['150-200'] += 1\n",
    "    elif len(i) < 500:\n",
    "        sent_length_dict['200-500'] += 1\n",
    "    else:\n",
    "        sent_length_dict['500+'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'100-': 4339,\n",
       "             '100-150': 14414,\n",
       "             '150-200': 8933,\n",
       "             '200-500': 27159,\n",
       "             '500+': 22325})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_length_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the training more efficient, we want to limit the length of text upto 150 char."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top most shown relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relations_stat_dict = defaultdict(int)\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        \n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        for attr in filtered_attrs:\n",
    "            if '_1:' in attr:\n",
    "                attr_label = attr.split(':')[0][:-2]\n",
    "                relations_stat_dict[attr_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Reps = 72831 minimum reps = 1264\n"
     ]
    }
   ],
   "source": [
    "top_relation_upto = 95\n",
    "\n",
    "top_most_shown_relations = {} # relation_label, number_of_times_it_shown\n",
    "sortedValues = sorted(relations_stat_dict.values(), reverse=True)\n",
    "max_value = sortedValues[0]\n",
    "top_top_value = sortedValues[top_relation_upto]\n",
    "print('Max Reps = '+str(max_value)+' minimum reps = '+str(top_top_value))\n",
    "\n",
    "for attr_label in relations_stat_dict:\n",
    "    attr_rep = relations_stat_dict[attr_label]\n",
    "    if attr_rep >= top_top_value:\n",
    "        top_most_shown_relations[attr_label] = attr_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the relation2id.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Remove the following relation labels for speeding up:\n",
    "del top_most_shown_relations['clubs']\n",
    "del top_most_shown_relations['years']\n",
    "del top_most_shown_relations['image']\n",
    "del top_most_shown_relations['name']\n",
    "del top_most_shown_relations['statlabel']\n",
    "del top_most_shown_relations['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 90 mostly shown relations:\n",
      "Minimum repetitions of an relationship = 1264\n",
      "{'position': 19386, 'bats': 2114, 'throws': 2118, 'birth_date': 63231, 'birth_place': 57087, 'debutdate': 2153, 'debutyear': 3285, 'debutteam': 2916, 'finaldate': 1644, 'finalyear': 2513, 'finalteam': 2249, 'statvalue': 3103, 'article_title': 72831, 'caption': 15338, 'residence': 4438, 'office': 5068, 'term_start': 7567, 'term_end': 6308, 'party': 6477, 'occupation': 18850, 'nationality': 13920, 'image_size': 6786, 'fullname': 13399, 'height': 12948, 'death_date': 21696, 'death_place': 16802, 'youthyears': 4163, 'youthclubs': 6033, 'caps': 10477, 'goals': 10875, 'nationalyears': 5350, 'nationalteam': 5787, 'nationalcaps': 5106, 'nationalgoals': 5080, 'background': 5965, 'birth_name': 9340, 'origin': 3620, 'instrument': 2784, 'genre': 6349, 'years_active': 7624, 'associated_acts': 3173, 'predecessor': 6879, 'successor': 6212, 'religion': 3923, 'parents': 1569, 'alma_mater': 6860, 'currentclub': 6975, 'clubnumber': 4298, 'pcupdate': 4628, 'ntupdate': 1882, 'title': 2428, 'profession': 2057, 'spouse': 8857, 'yearsactive': 2431, 'rank': 3089, 'known_for': 3314, 'birthname': 1275, 'order': 1807, 'country': 2324, 'year': 1499, 'date': 1452, 'source': 1791, 'league': 1378, 'team': 2572, 'number': 2005, 'height_ft': 2983, 'height_in': 2976, 'draft_year': 1265, 'career_start': 2341, 'allegiance': 2608, 'serviceyears': 2187, 'branch': 2741, 'battles': 2268, 'awards': 3575, 'weight': 4460, 'imagesize': 2930, 'field': 1924, 'nickname': 1497, 'shoots': 1264, 'weight_lb': 2094, 'manageryears': 1570, 'managerclubs': 1614, 'district': 1508, 'sport': 2762, 'updated': 1835, 'children': 4401, 'education': 1660, 'club': 2702, 'college': 3064, 'website': 3977}\n"
     ]
    }
   ],
   "source": [
    "print('Top '+str(len(top_most_shown_relations))+' mostly shown relations:')\n",
    "print('Minimum repetitions of an relationship = '+str(top_top_value))\n",
    "print(top_most_shown_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_type == 'train':\n",
    "    relation2idFile = open(data_type+'/relation2id.generate.txt', \"w\") \n",
    "    relation2idFile.write('NA 0\\n')\n",
    "    relationid = 1\n",
    "    for relation in top_most_shown_relations:\n",
    "        relation2idFile.write(relation+' '+str(relationid)+'\\n')\n",
    "        relationid += 1\n",
    "    relation2idFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Concatenated Relation Labels:\n",
    "Current, the relation labels are splitted in the wikipedia biography dataset.  \n",
    "In order to adapt to NRE code, we have to concatenate all splitted labels into one single string with underscore in between.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_relation_label_and_value_list = []\n",
    "chars_to_eliminate = ['\\'s',',','--',',','\\w','\\t','\\n','i','e.','m.','$','&','%','?','w.','.','-rsb-','\\'\\'','-lsb-','-']\n",
    "counter = 0\n",
    "\n",
    "with open(train_box_file) as boxes:\n",
    "    for one_entry in boxes:\n",
    "        \n",
    "        all_target_attributes = re.split(r'\\t+', one_entry)\n",
    "        filtered_attrs = [attr for attr in all_target_attributes if '<none>' not in attr]\n",
    "        \n",
    "        current_box_dict = {}\n",
    "        for oneLabel in filtered_attrs:\n",
    "            labelStringOnly = oneLabel.split(':')[0].split('_')[0]\n",
    "            \n",
    "            if labelStringOnly in top_most_shown_relations:\n",
    "                currentValue = cleanUpSentence(oneLabel.split(':')[1])\n",
    "                if not hasNumbers(currentValue) and currentValue not in chars_to_eliminate and len(currentValue) > 0:\n",
    "                    if labelStringOnly in current_box_dict:\n",
    "                        current_box_dict[labelStringOnly] = current_box_dict[labelStringOnly] + '_' + currentValue\n",
    "                    else:\n",
    "                        current_box_dict[labelStringOnly] = currentValue\n",
    "               \n",
    "        real_relation_label_and_value_list.append(current_box_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72831\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(real_relation_label_and_value_list))\n",
    "print(len(real_relation_label_and_value_list) == len(sent_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the training data txt file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the titles into a list, in original order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_list = []\n",
    "with open(train_title_file) as titles:\n",
    "    for title in titles:\n",
    "        title_arr = title.split(' ')\n",
    "        current_title = ''\n",
    "        for t in title_arr:\n",
    "            current_title += t+'_'\n",
    "        title_list.append(current_title[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the three lists (title_list, sent_dict, and real_relation_label_and_value_list) start with index 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miroslav_popov'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'miroslav popov born 14 june 1995 in dvůr králové nad labem is a czech grand prix motorcycle racer .he currently races in the fim cev moto2 championship for montaze broz racing team aboard a suter .'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cze_czech\n"
     ]
    }
   ],
   "source": [
    "for i in real_relation_label_and_value_list[2]:\n",
    "    print(real_relation_label_and_value_list[2][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Most Frequently Shown Second Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'50-': 63965, '10-': 79890, '20-': 88233, '50+': 15605})\n",
      "Max Reps = 3378 minimum reps = 201\n",
      "\n",
      "Top 100 most frequently shown second entities:\n",
      "{'right': 3378, 'june': 1105, 'solo_singer': 2741, 'vocals': 401, 'm_ftin_on': 2039, 'august': 1131, 'defender': 1925, 'attorney': 233, 'midfielder': 2506, 'goalkeeper': 1053, 'american': 3322, 'yes': 1079, 'england': 814, 'http_cricketarchive': 298, 'united_kingdom': 604, 'non_vocal_instrumentalist': 1137, 'non_performing_personnel': 327, 'french': 324, 'usa': 238, 'forward': 1441, 'september': 1380, 'right_wing': 223, 'left': 1773, 'june_utc': 368, 'october': 710, 'australian': 503, 'fencing': 317, 'canadian': 354, 'actress': 1023, 'present': 1023, 'roman_catholicism': 236, 'on': 272, 'kg_lb_on': 1176, 'athletics': 269, 'may': 1187, 'april': 1057, 'british': 1162, 'republican': 1027, 'http_cricinfo': 702, 'ft_in_m_on': 209, 'lb_kg_on': 230, 'actor': 1257, 'm_on': 435, 'striker': 1222, 'italian': 280, 'united_states': 930, 'center': 223, 'germany': 213, 'group_or_band': 1643, 'indian': 563, 'politician': 582, 'painting': 237, 'december': 433, 'http': 1396, 'right_back': 202, 'july': 990, 'pitcher': 837, 'conservative': 206, 'lawyer': 347, 'australia': 307, 'ndash_;': 650, 'cm_ftin_on': 313, 'unknown': 267, 'singer': 357, 'democratic': 807, 'winger': 328, 'free_agent': 239, 'roman_catholic': 508, 'march': 428, 'general': 208, 'mexican': 242, 'english': 365, 'united_states_of_america': 527, 'world_war_ii': 436, 'defence': 366, 'musician': 305, 'left_back': 237, 'august_utc': 221, 'writer': 241, 'february': 398, 'singer-songwriter': 201, 'kg_stlb_on': 459, 'november': 398, 'german': 313, 'outfielder': 268, 'liberal': 237, 'united_states_navy': 209, 'january': 446, 'new_zealand': 220, 'democrat': 346, 'nhl': 203, 'kg_lb': 206, 'left_wing': 227, 'centre': 215, 'united_states_army': 256, 'football': 371, 'kg_lb_st_on': 228, 'http_official_website': 237, 'islam': 328, 'attacking_midfielder': 206, 'centre_back': 299}\n"
     ]
    }
   ],
   "source": [
    "second_entity_length_dict = defaultdict(int)\n",
    "\n",
    "for r in real_relation_label_and_value_list:\n",
    "    for lable in r:\n",
    "        entity = r[lable]\n",
    "        l = len(entity)\n",
    "\n",
    "        if l < 10:\n",
    "            second_entity_length_dict['10-'] += 1\n",
    "        elif l < 20:\n",
    "            second_entity_length_dict['20-'] += 1\n",
    "        elif l < 50:\n",
    "            second_entity_length_dict['50-'] += 1\n",
    "        else:\n",
    "            second_entity_length_dict['50+'] += 1\n",
    "        \n",
    "print(second_entity_length_dict)   \n",
    "\n",
    "# second entity name, number of repetitions \n",
    "second_entity_dict = defaultdict(int) \n",
    "for r in real_relation_label_and_value_list:\n",
    "    for n in r:\n",
    "        entity = r[n]\n",
    "        second_entity_dict[entity] += 1\n",
    "        \n",
    "sortedSecondEntityDict = {} # relation_label, number_of_times_it_shown, in sorted order\n",
    "rank_upto = 100\n",
    "sortedValues = sorted(second_entity_dict.values(), reverse=True)\n",
    "max_value = sortedValues[0]\n",
    "top_top_value = sortedValues[rank_upto]\n",
    "print('Max Reps = '+str(max_value)+' minimum reps = '+str(top_top_value))\n",
    "\n",
    "for attr_label in second_entity_dict:\n",
    "    attr_rep = second_entity_dict[attr_label]\n",
    "    if attr_rep >= top_top_value:\n",
    "        sortedSecondEntityDict[attr_label] = attr_rep\n",
    "        \n",
    "print('\\nTop '+str(rank_upto)+' most frequently shown second entities:')\n",
    "print(sortedSecondEntityDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join three list by the biography title and write to text file:\n",
    "This is going to generate a 1+ GB large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultFile = open(data_type+'/'+data_type+\".generate.txt\", \"w\") \n",
    "\n",
    "index = 0\n",
    "\n",
    "for relationAndValueEntry in real_relation_label_and_value_list:\n",
    "    for relationName in relationAndValueEntry:\n",
    "        first_entity  = title_list[index]\n",
    "        second_entity = relationAndValueEntry[relationName]\n",
    "        if len(sent_dict[index]) < 150 and second_entity in sortedSecondEntityDict.keys():\n",
    "            resultFile.write('SH\\tSH\\t')\n",
    "            resultFile.write(first_entity)\n",
    "            resultFile.write('\\t')\n",
    "            resultFile.write(second_entity)\n",
    "            resultFile.write('\\t')\n",
    "            resultFile.write(relationName)\n",
    "            resultFile.write('\\t')\n",
    "            resultFile.write(sent_dict[index])\n",
    "            resultFile.write(' ###END###\\n')\n",
    "            \n",
    "    index += 1\n",
    "\n",
    "resultFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
